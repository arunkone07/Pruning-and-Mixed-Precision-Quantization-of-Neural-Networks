### 2x p + q
Accuracy before quantization: top1:  75.16  top5:  98.05
[<class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.linear.Linear'>]
size: 46935424
Acc after 8-bit (4x) compression: 75.15 98.06 

Total number of channels:  26570
channels quantized: 1132, acc: (75.1, 98.02), compression: 4.5x
channels quantized: 2637, acc: (74.84, 97.95), compression: 5.0x
channels quantized: 4361, acc: (74.95, 98.0), compression: 5.5x
channels quantized: 6959, acc: (74.94, 97.99), compression: 6.0x
channels quantized: 10166, acc: (74.83, 97.97), compression: 6.5x
channels quantized: 14102, acc: (74.72, 97.9), compression: 7.0x
channels quantized: 18824, acc: (74.5, 97.87), compression: 7.5x
18824/26570 channels quantized to 4-bit; acc: (74.5, 97.87), compression: 7.5x

Accuracy after quantization: top1:  74.5  top5:  97.87
Best quantized model saved to ./cifar10/checkpoint/p+q/rn50_2.pth

### 4x p + q
Accuracy before quantization: top1:  74.65  top5:  97.87
[<class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.linear.Linear'>]
size: 46935424
Acc after 8-bit (4x) compression: 74.65 97.87 

Total number of channels:  26570
channels quantized: 1132, acc: (74.63, 97.92), compression: 4.5x
channels quantized: 2639, acc: (74.63, 97.77), compression: 5.0x
channels quantized: 4642, acc: (74.55, 97.76), compression: 5.5x
channels quantized: 6991, acc: (74.36, 97.81), compression: 6.0x
channels quantized: 10409, acc: (74.21, 97.62), compression: 6.5x
channels quantized: 14152, acc: (74.26, 97.67), compression: 7.0x
channels quantized: 18884, acc: (74.51, 97.87), compression: 7.5x
18884/26570 channels quantized to 4-bit; acc: (74.51, 97.87), compression: 7.5x

Accuracy after quantization: top1:  74.51  top5:  97.87
Best quantized model saved to ./cifar10/checkpoint/p+q/rn50_4.pth

### 8x p + q
Accuracy before quantization: top1:  75.83  top5:  98.15
[<class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.linear.Linear'>]
size: 46935424
Acc after 8-bit (4x) compression: 75.82 98.15 

Total number of channels:  26570
channels quantized: 1137, acc: (75.76, 98.14), compression: 4.5x
channels quantized: 2705, acc: (75.67, 98.14), compression: 5.0x
channels quantized: 4977, acc: (75.3, 98.27), compression: 5.5x
channels quantized: 7382, acc: (75.23, 98.23), compression: 6.0x
channels quantized: 10879, acc: (75.2, 98.24), compression: 6.5x
channels quantized: 14438, acc: (75.23, 98.19), compression: 7.0x
channels quantized: 19046, acc: (75.17, 98.09), compression: 7.5x
19046/26570 channels quantized to 4-bit; acc: (75.17, 98.09), compression: 7.5x

Accuracy after quantization: top1:  75.17  top5:  98.09
Best quantized model saved to ./cifar10/checkpoint/p+q/rn50_8.pth

### 16x p + q
Accuracy before quantization: top1:  76.39  top5:  98.43
[<class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.linear.Linear'>]
size: 46935424
Acc after 8-bit (4x) compression: 10.0 50.0 

Total number of channels:  26570
channels quantized: 1260, acc: (10.0, 50.0), compression: 4.5x
channels quantized: 3087, acc: (10.0, 50.0), compression: 5.0x
channels quantized: 5722, acc: (10.0, 50.0), compression: 5.5x
channels quantized: 8634, acc: (10.0, 50.0), compression: 6.0x
channels quantized: 11840, acc: (10.0, 50.0), compression: 6.5x
channels quantized: 15177, acc: (10.0, 50.0), compression: 7.0x
channels quantized: 19418, acc: (10.0, 50.0), compression: 7.5x
19418/26570 channels quantized to 4-bit; acc: (10.0, 50.0), compression: 7.5x

Accuracy after quantization: top1:  10.0  top5:  50.0
Best quantized model saved to ./cifar10/checkpoint/p+q/rn50_16.pth