### Only q
Accuracy before quantization: top1:  79.48  top5:  98.27
[<class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.linear.Linear'>]
size: 29431168
Acc after 8-bit (4x) compression: 79.51 98.27 

Total number of channels:  4234
channels quantized: 710, acc: (79.5, 98.27), compression: 4.5x
channels quantized: 1278, acc: (79.34, 98.28), compression: 5.0x
channels quantized: 1742, acc: (79.3, 98.27), compression: 5.5x
channels quantized: 2129, acc: (79.25, 98.26), compression: 6.0x
channels quantized: 2457, acc: (79.18, 98.27), compression: 6.5x
channels quantized: 2915, acc: (79.11, 98.29), compression: 7.0x
channels quantized: 3402, acc: (79.35, 98.25), compression: 7.5x
3402/4234 channels quantized to 4-bit; acc: (79.35, 98.25), compression: 7.5x

Accuracy after quantization: top1:  79.35  top5:  98.25
Best quantized model saved to ./cifar10/checkpoint/quantized/v16.pth


### p+q
Accuracy before quantization: top1:  79.45  top5:  98.28
[<class 'torch.nn.modules.conv.Conv2d'>, <class 'torch.nn.modules.linear.Linear'>]
size: 29431168
Acc after 8-bit (4x) compression: 79.44 98.27 

Total number of channels:  4234
channels quantized: 710, acc: (79.41, 98.26), compression: 4.5x
channels quantized: 1278, acc: (79.34, 98.28), compression: 5.0x
channels quantized: 1742, acc: (79.37, 98.24), compression: 5.5x
channels quantized: 2129, acc: (79.22, 98.28), compression: 6.0x
channels quantized: 2457, acc: (79.2, 98.23), compression: 6.5x
channels quantized: 2915, acc: (79.16, 98.25), compression: 7.0x
channels quantized: 3402, acc: (79.32, 98.22), compression: 7.5x
3402/4234 channels quantized to 4-bit; acc: (79.32, 98.22), compression: 7.5x

Accuracy after quantization: top1:  79.32  top5:  98.22
Best quantized model saved to ./cifar10/checkpoint/p+q/v16.pth